{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression - Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_path=os.getcwd()\n",
    "print(current_path)\n",
    "\n",
    "parent_path=os.path.dirname(current_path)\n",
    "print(parent_path)\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning import pytorch as pl\n",
    "from pathlib import Path\n",
    "\n",
    "from chemprop import data, featurizers, models, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chemprop_dir = Path.cwd().parent\n",
    "num_workers = 20  # number of workers for dataloader. 0 means using main process for data loading\n",
    "# smiles_column = 'AAM'\n",
    "# target_columns = ['lograte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data splitting for training, validation, and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ReactionDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader \n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import MessagePassing, GCNConv, global_mean_pool\n",
    "\n",
    "# --- BƯỚC 1: ĐỊNH NGHĨA DATASET CHO PRE-TRAINING ---\n",
    "\n",
    "def get_reverse_edge_index(edge_index):\n",
    "    \"\"\"\n",
    "    Tính toán chỉ số của các cạnh ngược trong một đồ thị vô hướng.\n",
    "    \"\"\"\n",
    "    # Tạo một tensor để lưu kết quả\n",
    "    rev_edge_index = torch.zeros_like(edge_index[0])\n",
    "    \n",
    "    # Tạo một mapping từ cạnh (u, v) tới chỉ số của nó để tra cứu nhanh hơn\n",
    "    # Chuyển edge_index sang list các tuple để làm key cho dictionary\n",
    "    edge_map = {tuple(edge.tolist()): i for i, edge in enumerate(edge_index.T)}\n",
    "    \n",
    "    for i, edge in enumerate(edge_index.T):\n",
    "        # Lấy cạnh ngược (v, u)\n",
    "        rev_edge = tuple(edge.flip(0).tolist())\n",
    "        # Tìm chỉ số của cạnh ngược trong map\n",
    "        rev_idx = edge_map[rev_edge]\n",
    "        rev_edge_index[i] = rev_idx\n",
    "        \n",
    "    return rev_edge_index\n",
    "\n",
    "\n",
    "# 2. CẬP NHẬT LẠI DATASET\n",
    "class DGIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset này trả về một đối tượng Data của PyG cho mỗi đồ thị,\n",
    "    với các thuộc tính V, E, và rev_edge_index để tương thích với chemprop.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_attrs, edge_attrs, edge_indices):\n",
    "        self.node_attrs = node_attrs\n",
    "        self.edge_attrs = edge_attrs\n",
    "        self.edge_indices = edge_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.node_attrs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Lấy dữ liệu gốc\n",
    "        node_tensor = torch.tensor(self.node_attrs[idx], dtype=torch.float32)\n",
    "        edge_attr_tensor = torch.tensor(self.edge_attrs[idx], dtype=torch.float32)\n",
    "        edge_index_tensor = torch.tensor(self.edge_indices[idx], dtype=torch.long)\n",
    "        \n",
    "        # SỬA Ở ĐÂY: Tính toán và thêm rev_edge_index\n",
    "        rev_edge_index_tensor = get_reverse_edge_index(edge_index_tensor)\n",
    "\n",
    "        # Tạo đối tượng Data với đầy đủ các thuộc tính cần thiết\n",
    "        data = Data(\n",
    "            V=node_tensor,\n",
    "            E=edge_attr_tensor,\n",
    "            edge_index=edge_index_tensor,\n",
    "            rev_edge_index=rev_edge_index_tensor # Thêm vào đây\n",
    "        )\n",
    "        return data\n",
    "\n",
    "class SimpleGNNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        full().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        # Lưu lại output_dim để mô hình DGI có thể truy cập\n",
    "        self.output_dim = out_channels\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Lấy các thuộc tính cần thiết từ đối tượng Batch\n",
    "        x, edge_index = batch.x, batch.edge_index\n",
    "\n",
    "        # Truyền qua các lớp GNN\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# --- TẢI VÀ KẾT HỢP TẤT CẢ DỮ LIỆU ĐỂ PRE-TRAIN ---\n",
    "# Pre-training là tự giám sát nên chúng ta có thể dùng cả train/val/test data\n",
    "\n",
    "# Tải dữ liệu từ các file NPZ của bạn\n",
    "train_npz = np.load(f'../chemprop/data/RC/full/barriers_rgd1/barriers_rgd1_aam_train_rc_processed_data.npz', allow_pickle=True)\n",
    "val_npz = np.load(f'../chemprop/data/RC/full/barriers_rgd1/barriers_rgd1_aam_val_rc_processed_data.npz', allow_pickle=True)\n",
    "test_npz = np.load(f'../chemprop/data/RC/full/barriers_rgd1/barriers_rgd1_aam_test_rc_processed_data.npz', allow_pickle=True)\n",
    "\n",
    "# Kết hợp dữ liệu\n",
    "all_node_attrs = np.concatenate((train_npz['node_attrs'], val_npz['node_attrs'], test_npz['node_attrs']))\n",
    "all_edge_attrs = np.concatenate((train_npz['edge_attrs'], val_npz['edge_attrs'], test_npz['edge_attrs']))\n",
    "all_edge_indices = np.concatenate((train_npz['edge_indices'], val_npz['edge_indices'], test_npz['edge_indices']))\n",
    "\n",
    "print(f\"Tổng số mẫu để pre-train: {len(all_node_attrs)}\")\n",
    "\n",
    "# def get_reverse_edge_index(edge_index):\n",
    "#     \"\"\"Tính toán chỉ số của các cạnh ngược.\"\"\"\n",
    "#     rev_edge_index = torch.zeros_like(edge_index[0])\n",
    "#     for i in range(edge_index.shape[1]):\n",
    "#         # Tìm cạnh ngược (j, i) cho mỗi cạnh (i, j)\n",
    "#         edge_to_find = edge_index[:, i].flip(0)\n",
    "#         # So sánh để tìm vị trí\n",
    "#         matches = (edge_index.T == edge_to_find).all(dim=1)\n",
    "#         # Lấy chỉ số đầu tiên tìm thấy\n",
    "#         rev_idx = torch.where(matches)[0]\n",
    "#         if rev_idx.numel() > 0:\n",
    "#             rev_edge_index[i] = rev_idx[0]\n",
    "#         else:\n",
    "#             # Xử lý trường hợp không tìm thấy cạnh ngược (ít khả năng xảy ra nếu đồ thị là vô hướng)\n",
    "#             rev_edge_index[i] = -1 # hoặc một giá trị đặc biệt\n",
    "#     return rev_edge_index\n",
    "\n",
    "\n",
    "# def collate_pretraining_batch(samples):\n",
    "#     \"\"\"\n",
    "#     Hàm này sẽ gộp một list các sample (dictionaries) thành một batch duy nhất,\n",
    "#     đồng thời đảm bảo các thuộc tính V, E, và rev_edge_index được đặt tên đúng.\n",
    "#     \"\"\"\n",
    "#     batch_data = []\n",
    "#     for i, sample in enumerate(samples):\n",
    "#         edge_index = sample[\"edge_index\"]\n",
    "        \n",
    "#         # *** THÊM BƯỚC NÀY ***\n",
    "#         # Tính toán rev_edge_index\n",
    "#         rev_edge_index = get_reverse_edge_index(edge_index)\n",
    "\n",
    "#         data_point = Data(\n",
    "#             V=sample[\"masked_nodes\"],\n",
    "#             E=sample[\"masked_edges\"],\n",
    "#             edge_index=edge_index,\n",
    "            \n",
    "#             # Thêm rev_edge_index vào đối tượng Data\n",
    "#             rev_edge_index=rev_edge_index,\n",
    "            \n",
    "#             original_V=sample[\"original_nodes\"],\n",
    "#             node_mask_indices=sample[\"node_mask_indices\"],\n",
    "#             sample_idx=i\n",
    "#         )\n",
    "#         batch_data.append(data_point)\n",
    "\n",
    "#     return Batch.from_data_list(batch_data)\n",
    "\n",
    "# Khởi tạo lại DataLoader với collate_fn mới\n",
    "pretrain_dataset = DGIDataset(all_node_attrs, all_edge_attrs, all_edge_indices)\n",
    "pretrain_loader = DataLoader(pretrain_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Message-Passing Neural Network (MPNN) inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing\n",
    "\n",
    "Message passing blocks must be given the shape of the featurizer's outputs.\n",
    "\n",
    "Options are `mp = nn.BondMessagePassing()` or `mp = nn.AtomMessagePassing()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Discriminator(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Bộ phân loại (Discriminator) để so sánh embedding của nút và bản tóm tắt đồ thị.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, hidden_dim):\n",
    "#         super().__init__()\n",
    "#         # Sử dụng một lớp tuyến tính đơn giản làm hàm tính điểm bilinear\n",
    "#         self.bilinear = torch.nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "\n",
    "#     def forward(self, node_embeddings, summary_vec):\n",
    "#         # Tính tích vô hướng giữa embedding nút và summary đã được biến đổi\n",
    "#         # `sh` = transformed summary\n",
    "#         sh = self.bilinear(summary_vec)\n",
    "#         # `logits` có shape [số_nút_trong_batch]\n",
    "#         logits = torch.sum(node_embeddings * sh, dim=1)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "# class DGI_PretrainingMPNN(pl.LightningModule):\n",
    "#     \"\"\"\n",
    "#     Mô hình pre-training cho DGI.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, message_passing):\n",
    "#         super().__init__()\n",
    "#         # Lưu lại encoder để có thể truy cập sau này\n",
    "#         self.message_passing = message_passing\n",
    "#         hidden_dim = self.message_passing.output_dim\n",
    "        \n",
    "#         # 1. Khởi tạo Discriminator\n",
    "#         self.discriminator = Discriminator(hidden_dim)\n",
    "        \n",
    "#         # 2. Khởi tạo hàm loss\n",
    "#         self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "#         # Lưu lại để có thể gọi trong training_step\n",
    "#         self.save_hyperparameters(ignore=['message_passing'])\n",
    "\n",
    "#     def forward(self, batch):\n",
    "#         \"\"\"\n",
    "#         Thực hiện quá trình DGI: tạo embedding, summary, và tính điểm.\n",
    "#         \"\"\"\n",
    "#         # (1) Lấy node embeddings từ encoder\n",
    "#         # Giả sử message_passing trả về node embeddings có shape [tổng_số_nút, hidden_dim]\n",
    "#         node_embeddings = self.message_passing(batch)\n",
    "\n",
    "#         # (2) Tạo bản tóm tắt toàn cục cho mỗi đồ thị trong batch\n",
    "#         # summary_vec có shape [batch_size, hidden_dim]\n",
    "#         summary_vec = global_mean_pool(node_embeddings, batch.batch)\n",
    "\n",
    "#         # (3) Tạo các cặp Dương tính (Positive): (nút, đồ thị của nó)\n",
    "#         # Mở rộng summary_vec để mỗi nút có một bản sao của summary đồ thị của nó\n",
    "#         # positive_expanded_summary có shape [tổng_số_nút, hidden_dim]\n",
    "#         positive_expanded_summary = summary_vec[batch.batch]\n",
    "        \n",
    "#         # (4) Tạo các cặp Âm tính (Negative): (nút, đồ thị khác)\n",
    "#         # \"Làm hỏng\" (corrupt) các summary bằng cách xáo trộn chúng trong batch\n",
    "#         # Ví dụ: [s1, s2, s3] -> [s2, s3, s1]\n",
    "#         corrupted_summary_idx = torch.randperm(summary_vec.size(0))\n",
    "#         corrupted_summary_vec = summary_vec[corrupted_summary_idx]\n",
    "#         negative_expanded_summary = corrupted_summary_vec[batch.batch]\n",
    "\n",
    "#         # (5) Tính điểm cho cả hai loại cặp\n",
    "#         pos_score = self.discriminator(node_embeddings, positive_expanded_summary)\n",
    "#         neg_score = self.discriminator(node_embeddings, negative_expanded_summary)\n",
    "\n",
    "#         return pos_score, neg_score\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         pos_score, neg_score = self.forward(batch)\n",
    "\n",
    "#         # Tạo nhãn: 1 cho cặp dương tính, 0 cho cặp âm tính\n",
    "#         pos_labels = torch.ones_like(pos_score)\n",
    "#         neg_labels = torch.zeros_like(neg_score)\n",
    "        \n",
    "#         # Tính loss\n",
    "#         loss_pos = self.loss_fn(pos_score, pos_labels)\n",
    "#         loss_neg = self.loss_fn(neg_score, neg_labels)\n",
    "#         total_loss = loss_pos + loss_neg\n",
    "\n",
    "#         self.log(\"train_loss\", total_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "#         return total_loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn, optim\n",
    "from torch.nn import MSELoss\n",
    "from lightning import pytorch as pl\n",
    "\n",
    "from chemprop.data import BatchMolGraph\n",
    "from chemprop.nn import MessagePassing\n",
    "from chemprop.schedulers import build_NoamLike_LRSched\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Bộ phân loại (Discriminator) để so sánh embedding của nút và bản tóm tắt đồ thị.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Sử dụng một lớp tuyến tính đơn giản làm hàm tính điểm bilinear\n",
    "        self.bilinear = torch.nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, node_embeddings, summary_vec):\n",
    "        # Tính tích vô hướng giữa embedding nút và summary đã được biến đổi\n",
    "        # `sh` = transformed summary\n",
    "        sh = self.bilinear(summary_vec)\n",
    "        # `logits` có shape [số_nút_trong_batch]\n",
    "        logits = torch.sum(node_embeddings * sh, dim=1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DGI_PretrainingMPNN(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Mô hình pre-training cho DGI.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_passing: MessagePassing,\n",
    "        # node_feature_dim: int, # THÊM: Cần biết chiều của đặc trưng nút để tái tạo\n",
    "        warmup_epochs: int = 2,\n",
    "        init_lr: float = 1e-4,\n",
    "        max_lr: float = 1e-3,\n",
    "        final_lr: float = 1e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.message_passing = message_passing\n",
    "        hidden_dim = self.message_passing.output_dim\n",
    "        \n",
    "        # 1. Khởi tạo Discriminator\n",
    "        self.discriminator = Discriminator(hidden_dim)\n",
    "        \n",
    "        # 2. Khởi tạo hàm loss\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        # Lưu lại để có thể gọi trong training_step\n",
    "        self.save_hyperparameters(ignore=['message_passing'])\n",
    "        \n",
    "    def forward(self, batch: BatchMolGraph) -> Tensor:\n",
    "        \"\"\"\n",
    "        Thực hiện quá trình DGI: tạo embedding, summary, và tính điểm.\n",
    "        \"\"\"\n",
    "        # (1) Lấy node embeddings từ encoder\n",
    "        # Giả sử message_passing trả về node embeddings có shape [tổng_số_nút, hidden_dim]\n",
    "        node_embeddings = self.message_passing(batch)\n",
    "\n",
    "        # (2) Tạo bản tóm tắt toàn cục cho mỗi đồ thị trong batch\n",
    "        # summary_vec có shape [batch_size, hidden_dim]\n",
    "        summary_vec = global_mean_pool(node_embeddings, batch.batch)\n",
    "\n",
    "        # (3) Tạo các cặp Dương tính (Positive): (nút, đồ thị của nó)\n",
    "        # Mở rộng summary_vec để mỗi nút có một bản sao của summary đồ thị của nó\n",
    "        # positive_expanded_summary có shape [tổng_số_nút, hidden_dim]\n",
    "        positive_expanded_summary = summary_vec[batch.batch]\n",
    "        \n",
    "        # (4) Tạo các cặp Âm tính (Negative): (nút, đồ thị khác)\n",
    "        # \"Làm hỏng\" (corrupt) các summary bằng cách xáo trộn chúng trong batch\n",
    "        # Ví dụ: [s1, s2, s3] -> [s2, s3, s1]\n",
    "        corrupted_summary_idx = torch.randperm(summary_vec.size(0))\n",
    "        corrupted_summary_vec = summary_vec[corrupted_summary_idx]\n",
    "        negative_expanded_summary = corrupted_summary_vec[batch.batch]\n",
    "\n",
    "        # (5) Tính điểm cho cả hai loại cặp\n",
    "        pos_score = self.discriminator(node_embeddings, positive_expanded_summary)\n",
    "        neg_score = self.discriminator(node_embeddings, negative_expanded_summary)\n",
    "\n",
    "        return pos_score, neg_score\n",
    "\n",
    "\n",
    "    def training_step(self, batch: BatchMolGraph, batch_idx):\n",
    "        pos_score, neg_score = self.forward(batch)\n",
    "\n",
    "        # Tạo nhãn: 1 cho cặp dương tính, 0 cho cặp âm tính\n",
    "        pos_labels = torch.ones_like(pos_score)\n",
    "        neg_labels = torch.zeros_like(neg_score)\n",
    "        \n",
    "        # Tính loss\n",
    "        loss_pos = self.loss_fn(pos_score, pos_labels)\n",
    "        loss_neg = self.loss_fn(neg_score, neg_labels)\n",
    "        total_loss = loss_pos + loss_neg\n",
    "\n",
    "        self.log(\"train_loss\", total_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return total_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BƯỚC 3: KHỞI TẠO VÀ HUẤN LUYỆN MÔ HÌNH PRE-TRAINING (ĐÃ SỬA LỖI) ---\n",
    "from chemprop import nn\n",
    "from chemprop.nn import BondMessagePassing\n",
    "# Lấy thông số chiều từ dữ liệu\n",
    "node_feature_dim = pretrain_dataset.node_attrs[0].shape[1]\n",
    "edge_feature_dim = pretrain_dataset.edge_attrs[0].shape[1]\n",
    "fdims = (node_feature_dim, edge_feature_dim)\n",
    "\n",
    "# Khởi tạo encoder D-MPNN\n",
    "mp_encoder = BondMessagePassing(*fdims)\n",
    "# mp_encoder = nn.Linear(node_feature_dim, 128) # Tạm dùng Linear làm encoder ví dụ\n",
    "# mp_encoder.output_dim = 128\n",
    "\n",
    "# hidden_dim = 128\n",
    "# output_dim = 128 # output_dim của encoder\n",
    "\n",
    "# # Khởi tạo encoder GNN thực sự\n",
    "# mp_encoder = SimpleGNNEncoder(\n",
    "#     in_channels=node_feature_dim,\n",
    "#     hidden_channels=hidden_dim,\n",
    "#     out_channels=output_dim\n",
    "# )\n",
    "# Khởi tạo mô hình pre-training\n",
    "# SỬA Ở ĐÂY: Xóa `edge_feature_dim` khỏi lời gọi hàm\n",
    "pretrain_model = DGI_PretrainingMPNN(\n",
    "    message_passing=mp_encoder\n",
    ")\n",
    "\n",
    "# Khởi tạo Trainer của PyTorch Lightning\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50, \n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    logger=True\n",
    ")\n",
    "\n",
    "# Bắt đầu pre-training!\n",
    "print(\"Bắt đầu Pre-training...\")\n",
    "trainer.fit(pretrain_model, pretrain_loader)\n",
    "print(\"Pre-training hoàn tất!\")\n",
    "\n",
    "\n",
    "# --- BƯỚC 4: LƯU LẠI ENCODER ĐÃ ĐƯỢC HUẤN LUYỆN ---\n",
    "output_path = \"pretrained_dgi_dmpnn_nhap_encoder.pt\"\n",
    "torch.save(pretrain_model.message_passing.state_dict(), output_path)\n",
    "print(f\"Encoder đã pre-train được lưu tại: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
