{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression - Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_path=os.getcwd()\n",
    "print(current_path)\n",
    "\n",
    "parent_path=os.path.dirname(current_path)\n",
    "print(parent_path)\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning import pytorch as pl\n",
    "from pathlib import Path\n",
    "\n",
    "from chemprop import data, featurizers, models, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chemprop_dir = Path.cwd().parent\n",
    "num_workers = 0  # number of workers for dataloader. 0 means using main process for data loading\n",
    "# smiles_column = 'AAM'\n",
    "# target_columns = ['lograte']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data splitting for training, validation, and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ReactionDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# --- BƯỚC 1: ĐỊNH NGHĨA DATASET CHO PRE-TRAINING ---\n",
    "\n",
    "class MaskedFeatureDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset này sẽ:\n",
    "    1. Tải các features từ file NPZ.\n",
    "    2. Trong mỗi lần lấy dữ liệu (__getitem__), nó sẽ che ngẫu nhiên một phần \n",
    "       của node_attrs và edge_attrs.\n",
    "    3. Trả về cả dữ liệu gốc và dữ liệu đã bị che.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_attrs, edge_attrs, edge_indices, mask_fraction=0.15):\n",
    "        self.node_attrs = [torch.tensor(attrs, dtype=torch.float32) for attrs in node_attrs]\n",
    "        self.edge_attrs = [torch.tensor(attrs, dtype=torch.float32) for attrs in edge_attrs]\n",
    "        self.edge_indices = [torch.tensor(idx, dtype=torch.long) for idx in edge_indices]\n",
    "        self.mask_fraction = mask_fraction\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.node_attrs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Lấy dữ liệu gốc\n",
    "        original_nodes = self.node_attrs[idx]\n",
    "        original_edges = self.edge_attrs[idx]\n",
    "        edge_index = self.edge_indices[idx]\n",
    "\n",
    "        # Tạo bản sao để che\n",
    "        masked_nodes = original_nodes.clone()\n",
    "        masked_edges = original_edges.clone()\n",
    "\n",
    "        # Che ngẫu nhiên một phần node features\n",
    "        num_node_features_to_mask = int(original_nodes.shape[0] * self.mask_fraction)\n",
    "        node_mask_indices = torch.randperm(original_nodes.shape[0])[:num_node_features_to_mask]\n",
    "        masked_nodes[node_mask_indices] = 0.0 # Che bằng cách gán giá trị 0\n",
    "\n",
    "        # Che ngẫu nhiên một phần edge features\n",
    "        num_edge_features_to_mask = int(original_edges.shape[0] * self.mask_fraction)\n",
    "        edge_mask_indices = torch.randperm(original_edges.shape[0])[:num_edge_features_to_mask]\n",
    "        masked_edges[edge_mask_indices] = 0.0 # Che bằng cách gán giá trị 0\n",
    "        \n",
    "        return {\n",
    "            \"masked_nodes\": masked_nodes,\n",
    "            \"masked_edges\": masked_edges,\n",
    "            \"original_nodes\": original_nodes,\n",
    "            \"original_edges\": original_edges,\n",
    "            \"node_mask_indices\": node_mask_indices,\n",
    "            \"edge_mask_indices\": edge_mask_indices,\n",
    "            \"edge_index\": edge_index\n",
    "        }\n",
    "\n",
    "# --- TẢI VÀ KẾT HỢP TẤT CẢ DỮ LIỆU ĐỂ PRE-TRAIN ---\n",
    "# Pre-training là tự giám sát nên chúng ta có thể dùng cả train/val/test data\n",
    "\n",
    "# Tải dữ liệu từ các file NPZ của bạn\n",
    "train_npz = np.load(f'../chemprop/data/RC/full/barriers_rdb7/barriers_rdb7_aam_train_rc_processed_data.npz', allow_pickle=True)\n",
    "val_npz = np.load(f'../chemprop/data/RC/full/barriers_rdb7/barriers_rdb7_aam_val_rc_processed_data.npz', allow_pickle=True)\n",
    "test_npz = np.load(f'../chemprop/data/RC/full/barriers_rdb7/barriers_rdb7_aam_test_rc_processed_data.npz', allow_pickle=True)\n",
    "\n",
    "# Kết hợp dữ liệu\n",
    "all_node_attrs = np.concatenate((train_npz['node_attrs'], val_npz['node_attrs'], test_npz['node_attrs']))\n",
    "all_edge_attrs = np.concatenate((train_npz['edge_attrs'], val_npz['edge_attrs'], test_npz['edge_attrs']))\n",
    "all_edge_indices = np.concatenate((train_npz['edge_indices'], val_npz['edge_indices'], test_npz['edge_indices']))\n",
    "\n",
    "print(f\"Tổng số mẫu để pre-train: {len(all_node_attrs)}\")\n",
    "\n",
    "def get_reverse_edge_index(edge_index):\n",
    "    \"\"\"Tính toán chỉ số của các cạnh ngược.\"\"\"\n",
    "    rev_edge_index = torch.zeros_like(edge_index[0])\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        # Tìm cạnh ngược (j, i) cho mỗi cạnh (i, j)\n",
    "        edge_to_find = edge_index[:, i].flip(0)\n",
    "        # So sánh để tìm vị trí\n",
    "        matches = (edge_index.T == edge_to_find).all(dim=1)\n",
    "        # Lấy chỉ số đầu tiên tìm thấy\n",
    "        rev_idx = torch.where(matches)[0]\n",
    "        if rev_idx.numel() > 0:\n",
    "            rev_edge_index[i] = rev_idx[0]\n",
    "        else:\n",
    "            # Xử lý trường hợp không tìm thấy cạnh ngược (ít khả năng xảy ra nếu đồ thị là vô hướng)\n",
    "            rev_edge_index[i] = -1 # hoặc một giá trị đặc biệt\n",
    "    return rev_edge_index\n",
    "\n",
    "\n",
    "def collate_pretraining_batch(samples):\n",
    "    \"\"\"\n",
    "    Hàm này sẽ gộp một list các sample (dictionaries) thành một batch duy nhất,\n",
    "    đồng thời đảm bảo các thuộc tính V, E, và rev_edge_index được đặt tên đúng.\n",
    "    \"\"\"\n",
    "    batch_data = []\n",
    "    for i, sample in enumerate(samples):\n",
    "        edge_index = sample[\"edge_index\"]\n",
    "        \n",
    "        # *** THÊM BƯỚC NÀY ***\n",
    "        # Tính toán rev_edge_index\n",
    "        rev_edge_index = get_reverse_edge_index(edge_index)\n",
    "\n",
    "        data_point = Data(\n",
    "            V=sample[\"masked_nodes\"],\n",
    "            E=sample[\"masked_edges\"],\n",
    "            edge_index=edge_index,\n",
    "            \n",
    "            # Thêm rev_edge_index vào đối tượng Data\n",
    "            rev_edge_index=rev_edge_index,\n",
    "            \n",
    "            original_V=sample[\"original_nodes\"],\n",
    "            node_mask_indices=sample[\"node_mask_indices\"],\n",
    "            sample_idx=i\n",
    "        )\n",
    "        batch_data.append(data_point)\n",
    "\n",
    "    return Batch.from_data_list(batch_data)\n",
    "\n",
    "# Khởi tạo lại DataLoader với collate_fn mới\n",
    "pretrain_dataset = MaskedFeatureDataset(all_node_attrs, all_edge_attrs, all_edge_indices)\n",
    "pretrain_loader = DataLoader(pretrain_dataset, batch_size=32, shuffle=True, collate_fn=collate_pretraining_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Message-Passing Neural Network (MPNN) inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing\n",
    "\n",
    "Message passing blocks must be given the shape of the featurizer's outputs.\n",
    "\n",
    "Options are `mp = nn.BondMessagePassing()` or `mp = nn.AtomMessagePassing()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SỬA LẠI LỚP PRETRAININGMPNN\n",
    "\n",
    "from torch.nn import Linear, MSELoss \n",
    "\n",
    "from chemprop.data import BatchMolGraph\n",
    "from chemprop.nn import MessagePassing\n",
    "from chemprop.schedulers import build_NoamLike_LRSched\n",
    "\n",
    "class PretrainingMPNN(pl.LightningModule):\n",
    "    def __init__(self, message_passing, node_feature_dim):\n",
    "        super().__init__()\n",
    "        self.message_passing = message_passing\n",
    "        hidden_dim = self.message_passing.output_dim\n",
    "        self.node_prediction_head = Linear(hidden_dim, node_feature_dim)\n",
    "        self.loss_fn = MSELoss()\n",
    "        \n",
    "\n",
    "# Sửa trong lớp PretrainingMPNN\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Hàm forward của BondMessagePassing sẽ tự động dùng batch.V và batch.E\n",
    "        \n",
    "        # SỬA Ở ĐÂY: Gán kết quả cho một biến duy nhất\n",
    "        node_embeddings = self.message_passing(batch)\n",
    "        \n",
    "        predicted_node_features = self.node_prediction_head(node_embeddings)\n",
    "        return predicted_node_features\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "            predicted_nodes = self.forward(batch)\n",
    "            \n",
    "            # Tạo boolean mask cho toàn bộ batch\n",
    "            total_nodes = batch.V.shape[0] # Dùng batch.V thay vì batch.x\n",
    "            node_mask = torch.zeros(total_nodes, dtype=torch.bool, device=self.device)\n",
    "\n",
    "            base_idx = 0\n",
    "            for i in range(batch.num_graphs):\n",
    "                # Lấy các chỉ số mask cho từng đồ thị con trong batch\n",
    "                sample_mask_indices = batch.node_mask_indices[batch.batch == i]\n",
    "                \n",
    "                # Cập nhật mask tổng\n",
    "                node_mask[base_idx + sample_mask_indices] = True\n",
    "                \n",
    "                # Di chuyển đến điểm bắt đầu của đồ thị tiếp theo\n",
    "                num_nodes_in_sample = (batch.batch == i).sum()\n",
    "                base_idx += num_nodes_in_sample\n",
    "            \n",
    "            # Chỉ tính loss trên các node đã bị che\n",
    "            if node_mask.sum() > 0:\n",
    "                # Dùng batch.original_V để lấy feature gốc\n",
    "                loss = self.loss_fn(predicted_nodes[node_mask], batch.original_V[node_mask])\n",
    "                self.log(\"train_loss\", loss, prog_bar=True)\n",
    "                return loss\n",
    "                \n",
    "            return None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "            return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BƯỚC 3: KHỞI TẠO VÀ HUẤN LUYỆN MÔ HÌNH PRE-TRAINING (ĐÃ SỬA LỖI) ---\n",
    "\n",
    "# Lấy thông số chiều từ dữ liệu\n",
    "node_feature_dim = pretrain_dataset.node_attrs[0].shape[1]\n",
    "edge_feature_dim = pretrain_dataset.edge_attrs[0].shape[1]\n",
    "fdims = (node_feature_dim, edge_feature_dim)\n",
    "\n",
    "# Khởi tạo encoder D-MPNN\n",
    "mp_encoder = nn.BondMessagePassing(*fdims)\n",
    "\n",
    "# Khởi tạo mô hình pre-training\n",
    "# SỬA Ở ĐÂY: Xóa `edge_feature_dim` khỏi lời gọi hàm\n",
    "pretrain_model = PretrainingMPNN(\n",
    "    message_passing=mp_encoder, \n",
    "    node_feature_dim=node_feature_dim\n",
    ")\n",
    "\n",
    "# Khởi tạo Trainer của PyTorch Lightning\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200, \n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    enable_progress_bar=True,\n",
    "    logger=True\n",
    ")\n",
    "\n",
    "# Bắt đầu pre-training!\n",
    "print(\"Bắt đầu Pre-training...\")\n",
    "trainer.fit(pretrain_model, pretrain_loader)\n",
    "print(\"Pre-training hoàn tất!\")\n",
    "\n",
    "\n",
    "# --- BƯỚC 4: LƯU LẠI ENCODER ĐÃ ĐƯỢC HUẤN LUYỆN ---\n",
    "output_path = \"pretrained_dmpnn_encoder.pt\"\n",
    "torch.save(pretrain_model.message_passing.state_dict(), output_path)\n",
    "print(f\"Encoder đã pre-train được lưu tại: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
