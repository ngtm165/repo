{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning / Pretraining\n",
    "Transfer learning (or pretraining) leverages knowledge from a pre-trained model on a related task to enhance performance on a new task. In Chemprop, we can use pre-trained model checkpoints to initialize a new model and freeze components of the new model during training, as demonstrated in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chemprop/chemprop/blob/main/examples/transfer_learning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_path=os.getcwd()\n",
    "print(current_path)\n",
    "\n",
    "parent_path=os.path.dirname(current_path)\n",
    "print(parent_path)\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning import pytorch as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from chemprop import data, featurizers, models, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data inputs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemprop_dir = Path.cwd().parent\n",
    "input_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"mol\" / \"mol.csv\" # path to your data .csv file\n",
    "num_workers = 0 # number of workers for dataloader. 0 means using main process for data loading\n",
    "smiles_column = 'smiles' # name of the column containing SMILES strings\n",
    "target_columns = ['lipo'] # list of names of the columns containing targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chemprop_dir = Path.cwd().parent\n",
    "num_workers = 0  # number of workers for dataloader. 0 means using main process for data loading\n",
    "# smiles_column = 'AAM'\n",
    "# target_columns = ['lograte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"rxn\" / \"barriers_rdb7\" / \"train.csv\"\n",
    "train_npz = np.load(f'../chemprop/data/normal/barriers_rdb7/barriers_rdb7_aam_train_processed_data.npz', allow_pickle=True)\n",
    "train_v = train_npz['node_attrs']\n",
    "train_e = train_npz['edge_attrs']\n",
    "train_idx_g = train_npz['edge_indices']\n",
    "train_y = train_npz['ys'] \n",
    "\n",
    "val_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"rxn\" / \"barriers_rdb7\" / \"val.csv\"\n",
    "val_npz = np.load(f'../chemprop/data/normal/barriers_rdb7/barriers_rdb7_aam_val_processed_data.npz', allow_pickle=True)\n",
    "val_v = val_npz['node_attrs']\n",
    "val_e = val_npz['edge_attrs']\n",
    "val_idx_g = val_npz['edge_indices']\n",
    "val_y = val_npz['ys'] \n",
    "\n",
    "test_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"rxn\" / \"barriers_rdb7\" / \"test.csv\"\n",
    "test_npz = np.load(f'../chemprop/data/normal/barriers_rdb7/barriers_rdb7_aam_test_processed_data.npz', allow_pickle=True)\n",
    "test_v = test_npz['node_attrs']\n",
    "test_e = test_npz['edge_attrs']\n",
    "test_idx_g = test_npz['edge_indices']\n",
    "test_y = test_npz['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_idx_g.shape, val_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get molecule datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = data.ReactionDataset(train_v, train_e, train_idx_g, train_y)\n",
    "print(train_dset[0][3])\n",
    "scaler = train_dset.normalize_targets()\n",
    "# print(scaler)\n",
    "print(train_dset[0][3])\n",
    "\n",
    "val_dset = data.ReactionDataset(val_v, val_e, val_idx_g, val_y)\n",
    "val_dset.normalize_targets(scaler)\n",
    "test_dset = data.ReactionDataset(test_v, test_e, test_idx_g, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change checkpoint model inputs here\n",
    "Both message-passing neural networks (MPNNs) and multi-component MPNNs can have their weights initialized from a checkpoint file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemprop_dir = Path.cwd().parent\n",
    "checkpoint_path = chemprop_dir / \"tests\" / \"data\" / \"example_model_v2_regression_mol.ckpt\" # path to the checkpoint file.\n",
    "# If the checkpoint file is generated using the training notebook, it will be in the `checkpoints` folder with name similar to `checkpoints/epoch=19-step=180.ckpt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn_cls = models.MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn = mpnn_cls.load_from_file(checkpoint_path)\n",
    "mpnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale fine-tuning data with the model's target scaler\n",
    "\n",
    "If the pre-trained model was a regression model, it probably was trained on a scaled dataset. The scaler is saved as part of the model and used during prediction. For furthur training, we need to scale the fine-tuning data with the same target scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_scaler = StandardScaler()\n",
    "pretraining_scaler.mean_ = mpnn.predictor.output_transform.mean.numpy()\n",
    "pretraining_scaler.scale_ = mpnn.predictor.output_transform.scale.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MoleculeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = data.ReactionDataset(train_v, train_e, train_idx_g, train_y)\n",
    "train_dset.normalize_targets(pretraining_scaler)\n",
    "\n",
    "\n",
    "val_dset = data.ReactionDataset(val_v, val_e, val_idx_g, val_y)\n",
    "val_dset.normalize_targets(pretraining_scaler)\n",
    "test_dset = data.ReactionDataset(test_v, test_e, test_idx_g, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset[0][3]\n",
    "\n",
    "edge_index=train_dset[1][0][-2]\n",
    "print(f'edge_index: {edge_index}')\n",
    "reverse_index=train_dset[1][0][-1]\n",
    "print(f'reverse_index: {reverse_index}')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.arange(6).reshape(-1,2)[:, ::-1].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
    "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freezing MPNN and FFN layers\n",
    "Certain layers of a pre-trained model can be kept unchanged during further training on a new task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn.message_passing.apply(lambda module: module.requires_grad_(False))\n",
    "mpnn.message_passing.eval()\n",
    "mpnn.bn.apply(lambda module: module.requires_grad_(False))\n",
    "mpnn.bn.eval()  # Set batch norm layers to eval mode to freeze running mean and running var."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing FFN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frzn_ffn_layers = 1  # the number of consecutive FFN layers to freeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(frzn_ffn_layers):\n",
    "    mpnn.predictor.ffn[idx].requires_grad_(False)\n",
    "    mpnn.predictor.ffn[idx + 1].eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=20, # number of epochs to train for\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.test(mpnn, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with multicomponenent models\n",
    "Multi-component MPNN models have individual MPNN blocks for each molecule it parses in one input. These MPNN modules can be independently frozen for transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change data inputs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemprop_dir = Path.cwd().parent\n",
    "checkpoint_path = chemprop_dir / \"tests\" / \"data\" / \"example_model_v2_regression_mol+mol.ckpt\"  # path to the checkpoint file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change checkpoint model inputs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnn_cls = models.MulticomponentMPNN\n",
    "mcmpnn = mpnn_cls.load_from_checkpoint(checkpoint_path)\n",
    "mcmpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_to_freeze = [0, 1]  # a list of indices of the individual MPNN blocks to freeze before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmpnn = mpnn_cls.load_from_checkpoint(checkpoint_path)\n",
    "for i in blocks_to_freeze:\n",
    "    mp_block = mcmpnn.message_passing.blocks[i]\n",
    "    mp_block.apply(lambda module: module.requires_grad_(False))\n",
    "    mp_block.eval()\n",
    "mcmpnn.bn.apply(lambda module: module.requires_grad_(False))\n",
    "mcmpnn.bn.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
