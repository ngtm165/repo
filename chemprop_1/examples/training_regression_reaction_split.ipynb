{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression - Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_path=os.getcwd()\n",
    "print(current_path)\n",
    "\n",
    "parent_path=os.path.dirname(current_path)\n",
    "print(parent_path)\n",
    "\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "from lightning import pytorch as pl\n",
    "from pathlib import Path\n",
    "\n",
    "from chemprop import data, featurizers, models, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chemprop_dir = Path.cwd().parent\n",
    "num_workers = 20  # number of workers for dataloader. 0 means using main process for data loading\n",
    "# smiles_column = 'AAM'\n",
    "# target_columns = ['lograte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"rxn\" / \"barriers_rdb7\" / \"train.csv\"\n",
    "train_npz = np.load(f'../chemprop/data/normal/barriers_rdb7/barriers_rdb7_aam_train_processed_data.npz', allow_pickle=True)\n",
    "train_v = train_npz['node_attrs']\n",
    "train_e = train_npz['edge_attrs']\n",
    "train_idx_g = train_npz['edge_indices']\n",
    "train_y = train_npz['ys'] \n",
    "\n",
    "val_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"rxn\" / \"barriers_rdb7\" / \"val.csv\"\n",
    "val_npz = np.load(f'../chemprop/data/normal/barriers_rdb7/barriers_rdb7_aam_val_processed_data.npz', allow_pickle=True)\n",
    "val_v = val_npz['node_attrs']\n",
    "val_e = val_npz['edge_attrs']\n",
    "val_idx_g = val_npz['edge_indices']\n",
    "val_y = val_npz['ys'] \n",
    "\n",
    "test_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"rxn\" / \"barriers_rdb7\" / \"test.csv\"\n",
    "test_npz = np.load(f'../chemprop/data/normal/barriers_rdb7/barriers_rdb7_aam_test_processed_data.npz', allow_pickle=True)\n",
    "test_v = test_npz['node_attrs']\n",
    "test_e = test_npz['edge_attrs']\n",
    "test_idx_g = test_npz['edge_indices']\n",
    "test_y = test_npz['ys'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_idx_g.shape, val_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data splitting for training, validation, and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ReactionDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = data.ReactionDataset(train_v, train_e, train_idx_g, train_y)\n",
    "print(train_dset[0][3])\n",
    "scaler = train_dset.normalize_targets()\n",
    "# print(scaler)\n",
    "print(train_dset[0][3])\n",
    "\n",
    "val_dset = data.ReactionDataset(val_v, val_e, val_idx_g, val_y)\n",
    "val_dset.normalize_targets(scaler)\n",
    "test_dset = data.ReactionDataset(test_v, test_e, test_idx_g, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index=train_dset[1][0][-2]\n",
    "print(f'edge_index: {edge_index}')\n",
    "reverse_index=train_dset[1][0][-1]\n",
    "print(f'reverse_index: {reverse_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(6).reshape(-1,2)[:, ::-1].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
    "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Message-Passing Neural Network (MPNN) inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing\n",
    "\n",
    "Message passing blocks must be given the shape of the featurizer's outputs.\n",
    "\n",
    "Options are `mp = nn.BondMessagePassing()` or `mp = nn.AtomMessagePassing()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdims = (train_v[0].shape[1],train_e[0].shape[1]) # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mp = nn.BondMessagePassing(*fdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*fdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.agg.AggregationRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = nn.MeanAggregation()  #try Mean or Sum\n",
    "# agg = nn.SumAggregation()  #try Mean or Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Network (FFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.PredictorRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = nn.RegressionFFN(output_transform=output_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn.metrics.MetricRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [nn.metrics.RMSE(), nn.metrics.MAE()] \n",
    "# Only the first metric is used for training and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_jump = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpnn = models(mp, agg, ffn, batch_norm, metric_list, k_jump)\n",
    "# mpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpnn = models.MPNN_Simple(\n",
    "#     message_passing=mp,\n",
    "#     predictor=ffn,        \n",
    "#     # k_jump=k_jump,\n",
    "#     metrics=metric_list\n",
    "#     # init_lr=1e-4,\n",
    "#     # max_lr=1e-3,\n",
    "# )\n",
    "\n",
    "# print(\"Khởi tạo mô hình thành công!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(\n",
    "#     logger=False,\n",
    "#     enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "#     enable_progress_bar=True,\n",
    "#     accelerator=\"auto\",\n",
    "#     devices=1,\n",
    "#     max_epochs=200,  # number of epochs to train for\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = trainer.test(mpnn, test_loader)\n",
    "\n",
    "    # mpnn = models.MPNN_Simple(\n",
    "    # message_passing=mp,\n",
    "    # predictor=ffn,        \n",
    "    # # k_jump=k_jump,\n",
    "    # metrics=metric_list\n",
    "    # ) \n",
    "\n",
    "    # mpnn = models.MPNN_1(mp, agg, ffn, batch_norm, metric_list, FA_layer) \n",
    "    \n",
    "    #     mpnn = models.MPNN_MixHop_Pool(\n",
    "    # message_passing=mp,\n",
    "    # predictor=ffn,        \n",
    "    # metrics=metric_list\n",
    "    # ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# THAY THẾ TOÀN BỘ PHẦN \"Training and testing\" BẰNG ĐOẠN MÃ NÀY\n",
    "# ===================================================================\n",
    "\n",
    "# --- Thiết lập các tham số cho Ensemble ---\n",
    "ENSEMBLE_SIZE = 15\n",
    "all_test_results = []\n",
    "output_dir = Path(\"./reaction_ensemble_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Bắt đầu huấn luyện ensemble với kích thước = {ENSEMBLE_SIZE}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Bắt đầu vòng lặp huấn luyện Ensemble ---\n",
    "for i in range(ENSEMBLE_SIZE):\n",
    "    print(f\"\\n--- Đang huấn luyện mô hình {i+1}/{ENSEMBLE_SIZE} ---\")\n",
    "    \n",
    "    # 1. Tạo một mô hình MPNN mới cho mỗi lần lặp để đảm bảo trọng số được khởi tạo lại\n",
    "    mpnn = models.MPNN_Simple(\n",
    "    message_passing=mp,\n",
    "    predictor=ffn,        \n",
    "    metrics=metric_list\n",
    "    ) \n",
    "    \n",
    "    try:\n",
    "        pretrained_weights = torch.load(\"/home/labhhc2/Documents/workspace/D20/Tam/repo/chemprop_1/examples/pretrained_dmpnn_nhap_encoder.pt\")\n",
    "        mpnn.message_passing.load_state_dict(pretrained_weights)\n",
    "        print(f\"Model {i+1}: Tải trọng số pre-train thành công!\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model {i+1}: Không tìm thấy file pre-trained. Huấn luyện từ đầu.\")\n",
    "    \n",
    "    # 2. Tạo một Trainer mới, chỉ định nơi lưu checkpoint cho từng mô hình\n",
    "    model_checkpoint_dir = output_dir / f\"model_{i}\"\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=model_checkpoint_dir,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        filename='best_model'\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=False,\n",
    "        enable_checkpointing=True,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        enable_progress_bar=True,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=50,\n",
    "    )\n",
    "    \n",
    "    # 3. Huấn luyện mô hình\n",
    "    trainer.fit(mpnn, train_loader, val_loader)\n",
    "    \n",
    "    # 4. Chạy kiểm tra (test) trên mô hình tốt nhất vừa được lưu\n",
    "    # và lưu kết quả của lần lặp này\n",
    "    print(f\"--- Đang kiểm tra mô hình {i+1} ---\")\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    results = trainer.test(mpnn, test_loader, ckpt_path=best_model_path)\n",
    "    all_test_results.append(results[0]) # results là một list, lấy phần tử đầu tiên\n",
    "\n",
    "# --- Tổng hợp kết quả ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"HUẤN LUYỆN ENSEMBLE HOÀN TẤT!\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Chuyển danh sách kết quả thành DataFrame để dễ tính toán\n",
    "results_df = pd.DataFrame(all_test_results)\n",
    "\n",
    "print(\"\\n--- Kết quả kiểm tra của từng mô hình ---\")\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\n--- Kết quả trung bình của Ensemble ---\")\n",
    "print(results_df.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
